{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ac0f5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 470ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import keras \n",
    "import numpy as np\n",
    "import librosa\n",
    "import sounddevice as sd\n",
    "import wavio\n",
    "\n",
    "class LivePredictionsApp:\n",
    "    def __init__(self):\n",
    "        # This is the constructor method that initializes the attributes of the class\n",
    "        self.window = tk.Tk() # This creates a tkinter window object\n",
    "        self.window.title(\"Live Speech Emotion Detection\") # This sets the title of the window\n",
    "        self.window.geometry(\"600x400\") # This sets the size of the window\n",
    "\n",
    "        # Configure window background color and font settings\n",
    "        self.window.configure(bg=\"#F0F0F0\") # This sets the background color of the window\n",
    "        self.label_font = (\"Arial\", 18, \"bold\") # This defines a font for labels\n",
    "        self.button_font = (\"Arial\", 14) # This defines a font for buttons\n",
    "        self.result_font = (\"Arial\", 16, \"bold\") # This defines a font for results\n",
    "\n",
    "        self.label = tk.Label(self.window, text=\"Upload an audio file:\", font=self.label_font, bg=\"#F0F0F0\", fg=\"#007AFF\") # This creates a label widget with some text and font settings\n",
    "        self.label.pack(pady=20) # This places the label in the window with some padding\n",
    "\n",
    "        self.upload_button = tk.Button(self.window, text=\"Upload\", command=self.upload_file, bg=\"#007AFF\", fg=\"white\", font=self.button_font) # This creates a button widget that calls the upload_file method when clicked\n",
    "        self.upload_button.pack(pady=10) # This places the button in the window with some padding\n",
    "\n",
    "        self.record_button = tk.Button(self.window, text=\"Record\", command=self.record_voice, bg=\"#007AFF\", fg=\"white\", font=self.button_font) # This creates another button widget that calls the record_voice method when clicked\n",
    "        self.record_button.pack(pady=10) # This places the button in the window with some padding\n",
    "\n",
    "        self.prediction_label = tk.Label(self.window, text=\"\", font=self.result_font, bg=\"#F0F0F0\", fg=\"#007AFF\") # This creates another label widget that will display the prediction result\n",
    "        self.prediction_label.pack(pady=20) # This places the label in the window with some padding\n",
    "\n",
    "        self.path = \"\" # This is an attribute that will store the path of the audio file\n",
    "        self.model_path = r'E:\\#1 DATA SCIENCE\\#4 Deep Learning\\Projects\\Speech Emotion Detection\\SER_MODEL\\SER_model.h5' # This is an attribute that stores the path of the keras model\n",
    "        \n",
    "    def upload_file(self):\n",
    "        # This is a method that allows the user to upload an audio file from their computer\n",
    "        self.path = filedialog.askopenfilename(title=\"Select an audio file\", filetypes=[(\"Audio Files\", \"*.wav\")]) # This opens a file dialog and returns the path of the selected file\n",
    "        if self.path: # If a file was selected\n",
    "            self.make_predictions() # Call the make_predictions method\n",
    "\n",
    "    def record_voice(self):\n",
    "        # This is a method that allows the user to record their voice using their microphone\n",
    "        fs = 44100  # Sample rate\n",
    "        seconds = 5  # Duration of recording\n",
    "\n",
    "        print(\"Recording...\") \n",
    "        recording = sd.rec(int(fs * seconds), samplerate=fs, channels=1, dtype='int16') # This uses the sounddevice module to record audio data as an array\n",
    "        sd.wait() # This waits until the recording is finished\n",
    "        print(\"Finished recording.\")\n",
    "\n",
    "        WAVE_OUTPUT_FILENAME = \"recorded_audio.wav\" \n",
    "        wavio.write(WAVE_OUTPUT_FILENAME, recording, fs, sampwidth=2) # This uses the wavio module to write the audio data as a wav file\n",
    "\n",
    "        self.path = WAVE_OUTPUT_FILENAME # Set the path attribute to the wav file name\n",
    "        self.make_predictions() # Call the make_predictions method\n",
    "\n",
    "    def make_predictions(self):\n",
    "        # This is a method that uses the keras model to predict the emotion of the speaker in the audio file\n",
    "        data, sampling_rate = librosa.load(self.path) # This uses the librosa module to load the audio data and sampling rate from the file\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0) # This uses the librosa module to extract mfcc features from the audio data and compute their mean along each frame\n",
    "        x = np.expand_dims(mfccs, axis=1) # This adds a new dimension to the mfcc array to match the input shape of the model\n",
    "        x = np.expand_dims(x, axis=0) # This adds another new dimension to the mfcc array to match the input shape of the model\n",
    "\n",
    "        loaded_model = keras.models.load_model(self.model_path) # This loads the keras model from the file\n",
    "        predictions = loaded_model.predict(x) # This uses the model to make predictions on the mfcc array\n",
    "        predicted_class = np.argmax(predictions, axis=1)[0] # This finds the index of the highest prediction value and assigns it to the predicted class\n",
    "        predicted_emotion = self.convert_class_to_emotion(predicted_class) # This converts the predicted class to a corresponding emotion using a helper method\n",
    "\n",
    "        self.prediction_label.config(text=\"Prediction: \" + predicted_emotion, fg=\"#007AFF\") # This updates the prediction label with the predicted emotion\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_class_to_emotion(pred):\n",
    "        # This is a helper method that maps a numerical class to an emotion label\n",
    "        label_conversion = {0: 'neutral', 1: 'calm', 2: 'happy', 3: 'sad', 4: 'angry', 5: 'fearful', 6: 'disgust', 7: 'surprised'} # This is a dictionary that stores the mapping\n",
    "        return label_conversion.get(pred, 'Unknown') # This returns the emotion label for the given class or 'Unknown' if not found\n",
    "\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        self.window.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = LivePredictionsApp()\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb037c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
